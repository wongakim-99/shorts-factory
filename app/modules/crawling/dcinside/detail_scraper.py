"""
DC ì¸ì‚¬ì´ë“œ í¬ë¡¤ë§ ë¡œì§ë§Œ ë‹´ë‹¹
ë‚˜ì¤‘ì— naver ë‰´ìŠ¤, reddit ë“±ë“± ì¶”ê°€ ê°€ëŠ¥

í•´ë‹¹ íŒŒì¼ì—ì„œëŠ” DCì¸ì‚¬ì´ë“œ ìƒì„¸ ëª©ë¡(detail)ì— ëŒ€í•œ í¬ë¡¤ë§ ë‹´ë‹¹
"""

import os
import logging
import requests
import hashlib
import shutil
import time as time_module
from datetime import datetime, timedelta

from pathlib import Path
from typing import List, Dict, Optional
from bs4 import BeautifulSoup

# Selenium ê´€ë ¨
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options

from app.modules.crawling.dcinside.constants import GALLERY_ID, BASE_URL, HEADERS

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def cleanup_old_images(keep_days: int = 7):
    """
    ì˜¤ë˜ëœ ì´ë¯¸ì§€ í´ë” ìë™ ì‚­ì œ
    
    Args:
        keep_days: ë³´ê´€ ê¸°ê°„ (ì¼). ì´ë³´ë‹¤ ì˜¤ë˜ëœ í´ë”ëŠ” ì‚­ì œ
    """
    try:
        images_base_dir = Path("app/output/images")
        if not images_base_dir.exists():
            return
        
        cutoff_date = datetime.now() - timedelta(days=keep_days)
        deleted_count = 0
        
        # ë‚ ì§œ í˜•ì‹ í´ë”ë§Œ í™•ì¸ (YYYY-MM-DD)
        for folder in images_base_dir.iterdir():
            if not folder.is_dir():
                continue
            
            try:
                # í´ë”ëª…ì´ ë‚ ì§œ í˜•ì‹ì¸ì§€ í™•ì¸
                folder_date = datetime.strptime(folder.name, '%Y-%m-%d')
                
                # ì˜¤ë˜ëœ í´ë” ì‚­ì œ
                if folder_date < cutoff_date:
                    shutil.rmtree(folder)
                    deleted_count += 1
                    logger.info(f"ğŸ—‘ï¸ ì˜¤ë˜ëœ ì´ë¯¸ì§€ í´ë” ì‚­ì œ: {folder.name}")
            except ValueError:
                # ë‚ ì§œ í˜•ì‹ì´ ì•„ë‹Œ í´ë”ëŠ” ë¬´ì‹œ
                continue
        
        if deleted_count > 0:
            logger.info(f"âœ… ì´ {deleted_count}ê°œ í´ë” ì •ë¦¬ ì™„ë£Œ")
        else:
            logger.info(f"âœ… ì •ë¦¬í•  ì˜¤ë˜ëœ ì´ë¯¸ì§€ ì—†ìŒ (ë³´ê´€ ê¸°ê°„: {keep_days}ì¼)")
            
    except Exception as e:
        logger.warning(f"âš ï¸ ì´ë¯¸ì§€ ì •ë¦¬ ì‹¤íŒ¨: {e}")


def get_comments_with_selenium(post_id: str) -> List[str]:
    """
    Seleniumì„ ì‚¬ìš©í•˜ì—¬ ëŒ“ê¸€ í¬ë¡¤ë§ (JavaScript ë™ì  ë¡œë”© ëŒ€ì‘)
    
    Args:
        post_id: ê²Œì‹œê¸€ ë²ˆí˜¸
    
    Returns:
        ëŒ“ê¸€ ë¦¬ìŠ¤íŠ¸
    """
    comments = []
    
    try:
        # Chrome/Chromium ì˜µì…˜ ì„¤ì • (headless ëª¨ë“œ)
        chrome_options = Options()
        chrome_options.add_argument('--headless')  # ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--window-size=1920,1080')
        chrome_options.add_argument(f'user-agent={HEADERS["User-Agent"]}')
        chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        
        # ë¡œê·¸ ìµœì†Œí™”
        chrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])
        
        # Chromium ë°”ì´ë„ˆë¦¬ ê²½ë¡œ ì„¤ì • (Docker í™˜ê²½)
        # macOSì—ì„œëŠ” ìë™ìœ¼ë¡œ Chrome ì°¾ìŒ, Dockerì—ì„œëŠ” chromium ì‚¬ìš©
        try:
            chrome_options.binary_location = '/usr/bin/chromium'
        except:
            pass  # macOSëŠ” ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©
        
        # WebDriver ìƒì„±
        driver = webdriver.Chrome(options=chrome_options)
        
        # í˜ì´ì§€ ì ‘ì†
        url = f"https://gall.dcinside.com/mgallery/board/view?id={GALLERY_ID}&no={post_id}"
        driver.get(url)
        
        # ëŒ“ê¸€ ì˜ì—­ ë¡œë”© ëŒ€ê¸° (ìµœëŒ€ 10ì´ˆ)
        try:
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CLASS_NAME, "comment_wrap"))
            )
            
            # ì¶”ê°€ ëŒ€ê¸° (ëŒ“ê¸€ ë¡œë”© ì™„ë£Œ)
            time_module.sleep(2)
            
            # ëŒ“ê¸€ ìˆ˜ í™•ì¸
            comment_total_elem = driver.find_element(By.ID, f"comment_total_{post_id}")
            comment_count = int(comment_total_elem.text)
            
            if comment_count == 0:
                logger.info(f"  ğŸ’¬ ëŒ“ê¸€ ì—†ìŒ")
                driver.quit()
                return []
            
            logger.info(f"  ğŸ’¬ ëŒ“ê¸€ {comment_count}ê°œ ë°œê²¬")
            
            # BeautifulSoupìœ¼ë¡œ íŒŒì‹±
            soup = BeautifulSoup(driver.page_source, 'lxml')
            
            # ëŒ“ê¸€ <li> ìš”ì†Œ ì°¾ê¸°
            comment_list = soup.select('ul.cmt_list li')
            
            if not comment_list:
                comment_list = soup.select('.comment_wrap li')
            
            logger.info(f"  ğŸ” ëŒ“ê¸€ <li> ìš”ì†Œ {len(comment_list)}ê°œ ë°œê²¬")
            
            for li in comment_list:
                # ê´‘ê³ ì„± ëŒ“ê¸€ ì œì™¸
                li_classes = li.get('class', [])
                if 'dory' in li_classes or 'ad' in li_classes:
                    continue
                
                # í…ìŠ¤íŠ¸ ëŒ“ê¸€ ì°¾ê¸° (.usertxt ìš°ì„ )
                comment_text_elem = li.select_one('.usertxt')
                
                if comment_text_elem:
                    comment_text = comment_text_elem.get_text(strip=True)
                    
                    # "ë””ì‹œì½˜ ë³´ê¸°" ê°™ì€ ë²„íŠ¼ í…ìŠ¤íŠ¸ ì œì™¸
                    if comment_text and len(comment_text) > 0 and comment_text != "ë””ì‹œì½˜ ë³´ê¸°":
                        # ëŒ€ëŒ“ê¸€ ì—¬ë¶€ í™•ì¸
                        is_reply = 'reply' in li_classes or li.find_parent('ul', class_='reply_list')
                        if is_reply:
                            comments.append(f"â”” {comment_text}")
                        else:
                            comments.append(comment_text)
            
            # ì¤‘ë³µ ì œê±°
            comments = list(dict.fromkeys(comments))
            
            logger.info(f"  âœ… Selenium ëŒ“ê¸€ ìˆ˜ì§‘ ì™„ë£Œ: {len(comments)}ê°œ")
            
        except Exception as e:
            logger.warning(f"  âš ï¸ ëŒ“ê¸€ ë¡œë”© ëŒ€ê¸° ì‹¤íŒ¨: {e}")
        
        finally:
            driver.quit()
    
    except Exception as e:
        logger.error(f"  âŒ Selenium ëŒ“ê¸€ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
    
    return comments


def download_image(image_url: str, post_id: str, img_index: int) -> Optional[str]:
    """
    ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (403 ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ Referer í—¤ë” í¬í•¨)
    
    Args:
        image_url: ì´ë¯¸ì§€ URL
        post_id: ê²Œì‹œê¸€ ID
        img_index: ì´ë¯¸ì§€ ìˆœì„œ
    
    Returns:
        ì €ì¥ëœ ì´ë¯¸ì§€ì˜ ë¡œì»¬ ê²½ë¡œ (ì‹¤íŒ¨ ì‹œ None)
    """
    try:
        # ë‚ ì§œë³„ ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„± (YYYY-MM-DD í˜•ì‹)
        today = datetime.now().strftime('%Y-%m-%d')
        images_dir = Path(f"app/output/images/{today}")
        images_dir.mkdir(parents=True, exist_ok=True)
        
        # Referer í—¤ë” ì¶”ê°€ (DCInsideì—ì„œ ì˜¤ëŠ” ê²ƒì²˜ëŸ¼ ìœ„ì¥)
        headers = HEADERS.copy()
        headers['Referer'] = f'https://gall.dcinside.com/mgallery/board/view/?id={GALLERY_ID}&no={post_id}'
        
        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        response = requests.get(image_url, headers=headers, timeout=10)
        response.raise_for_status()
        
        # íŒŒì¼ í™•ì¥ì ì¶”ì¶œ
        ext = image_url.split('.')[-1].split('?')[0]  # URL íŒŒë¼ë¯¸í„° ì œê±°
        if ext.lower() not in ['jpg', 'jpeg', 'png', 'gif', 'webp']:
            ext = 'jpg'  # ê¸°ë³¸ í™•ì¥ì
        
        # íŒŒì¼ëª… ìƒì„± (ê²Œì‹œê¸€ID_ìˆœì„œ.í™•ì¥ì)
        filename = f"{post_id}_{img_index:02d}.{ext}"
        filepath = images_dir / filename
        
        # ì´ë¯¸ì§€ ì €ì¥
        with open(filepath, 'wb') as f:
            f.write(response.content)
        
        logger.info(f"  ğŸ“¸ ì´ë¯¸ì§€ ì €ì¥: {filename}")
        return str(filepath)
        
    except Exception as e:
        logger.warning(f"  âš ï¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ({image_url}): {e}")
        return None


# ê°¤ëŸ¬ë¦¬ ê²Œì‹œê¸€ ë””í…Œì¼ í¬ë¡¤ë§
def get_post_detail(post_id: str, download_images: bool = True, debug: bool = False) -> Optional[Dict]:
    """
    ê²Œì‹œê¸€ ë³¸ë¬¸ í¬ë¡¤ë§

    Args:
        post_id: ê²Œì‹œê¸€ ë²ˆí˜¸
        download_images: ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì—¬ë¶€ (ê¸°ë³¸: True)
        debug: ë””ë²„ê·¸ ëª¨ë“œ (HTML ì €ì¥ ë° ìƒì„¸ ë¡œê·¸)

    Returns:
        {'post_id', 'title', 'author', 'content', 'images', 'image_paths', 'comments'}
    """
    url = f"https://gall.dcinside.com/mgallery/board/view"
    params = {
        'id': GALLERY_ID,
        'no': post_id,
    }

    try:
        response = requests.get(url, params=params, headers=HEADERS, timeout=10)
        response.raise_for_status()

        soup = BeautifulSoup(response.text, 'lxml')

        # ë””ë²„ê·¸ ëª¨ë“œ: HTML ì €ì¥ ë° ëŒ“ê¸€ ì˜ì—­ ë¶„ì„
        if debug:
            debug_dir = Path("app/output/debug")
            debug_dir.mkdir(parents=True, exist_ok=True)
            
            # ì „ì²´ HTML ì €ì¥
            with open(debug_dir / f"post_{post_id}.html", 'w', encoding='utf-8') as f:
                f.write(response.text)
            logger.info(f"  ğŸ› DEBUG: HTML ì €ì¥ë¨ â†’ app/output/debug/post_{post_id}.html")
            
            # ëŒ“ê¸€ ì˜ì—­ ë¶„ì„
            comment_area = soup.find('div', class_='comment_wrap') or soup.find('div', class_='cmt_area')
            if comment_area:
                logger.info(f"  ğŸ› DEBUG: ëŒ“ê¸€ ì˜ì—­ ë°œê²¬")
                logger.info(f"  ğŸ› DEBUG: ul.cmt_list ê°œìˆ˜: {len(comment_area.select('ul.cmt_list'))}")
                logger.info(f"  ğŸ› DEBUG: li ê°œìˆ˜: {len(comment_area.find_all('li'))}")
            else:
                logger.warning(f"  ğŸ› DEBUG: ëŒ“ê¸€ ì˜ì—­ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ!")

        # ì œëª©
        title_elem = soup.select_one('span.title_subject')
        title = title_elem.text.strip() if title_elem else ''

        # ì‘ì„±ì
        author_elem = soup.select_one('div.gall_writer')
        author = author_elem.get('data-nick', 'ìµëª…') if author_elem else 'ìµëª…'

        # ë³¸ë¬¸ ì˜ì—­ ì°¾ê¸°
        content_elem = soup.select_one('div.write_div')
        
        # ì´ë¯¸ì§€ URL ë¨¼ì € ìˆ˜ì§‘ (decompose ì „ì—!)
        images = []  # ì›ë³¸ URL
        image_paths = []  # ë‹¤ìš´ë¡œë“œëœ ë¡œì»¬ ê²½ë¡œ
        
        if content_elem:
            img_index = 0
            for img in content_elem.find_all('img'):
                src = img.get('src', '')
                if src and src.startswith('http'):
                    images.append(src)
                    
                    # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                    if download_images:
                        local_path = download_image(src, post_id, img_index)
                        if local_path:
                            image_paths.append(local_path)
                    img_index += 1
        
        # ë³¸ë¬¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì´ë¯¸ì§€ íƒœê·¸ ì œê±°)
        if content_elem:
            # ì´ë¯¸ì§€ íƒœê·¸ ì œê±°í•˜ê³  í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
            for img in content_elem.find_all('img'):
                img.decompose()
            content = content_elem.get_text(separator='\n', strip=True)
        else:
            content = ''

        # ëŒ“ê¸€ ìˆ˜ì§‘ (Selenium ì‚¬ìš© - JavaScript ë™ì  ë¡œë”© ëŒ€ì‘)
        comments = get_comments_with_selenium(post_id)

        logger.info(f"ğŸ“ ê²Œì‹œê¸€ {post_id} ë³¸ë¬¸ ìˆ˜ì§‘ ì™„ë£Œ (ë³¸ë¬¸ {len(content)}ì, ì´ë¯¸ì§€ {len(image_paths)}ê°œ, ëŒ“ê¸€ {len(comments)}ê°œ)")

        return {
            'post_id': post_id,
            'title': title,
            'author': author,
            'content': content,
            'images': images,  # ì›ë³¸ URL (ì°¸ê³ ìš©)
            'image_paths': image_paths,  # ë‹¤ìš´ë¡œë“œëœ ë¡œì»¬ ê²½ë¡œ
            'comments': comments,
        }

    except requests.RequestException as e:  # ê²Œì‹œê¸€ ìš”ì²­ì— ëŒ€í•œ ì‹¤íŒ¨ì— ëŒ€í•œ ì˜ˆì™¸ì²˜ë¦¬
        logger.error(f"âŒ ê²Œì‹œê¸€ {post_id} ìš”ì²­ ì‹¤íŒ¨: {e}")
        return None

    except Exception as e:  # ê²Œì‹œê¸€ íŒŒì‹± ì‹¤íŒ¨ì— ëŒ€í•œ ì˜ˆì™¸ì²˜ë¦¬
        logger.error(f"âŒ ê²Œì‹œê¸€ {post_id} íŒŒì‹± ì‹¤íŒ¨: {e}")
        return None