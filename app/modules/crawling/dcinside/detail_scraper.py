"""
DC ì¸ì‚¬ì´ë“œ í¬ë¡¤ë§ ë¡œì§ë§Œ ë‹´ë‹¹
ë‚˜ì¤‘ì— naver ë‰´ìŠ¤, reddit ë“±ë“± ì¶”ê°€ ê°€ëŠ¥

í•´ë‹¹ íŒŒì¼ì—ì„œëŠ” DCì¸ì‚¬ì´ë“œ ìƒì„¸ ëª©ë¡(detail)ì— ëŒ€í•œ í¬ë¡¤ë§ ë‹´ë‹¹
"""

import logging
import requests

from typing import List, Dict, Optional
from bs4 import BeautifulSoup

from .constants import GALLERY_ID, BASE_URL, HEADERS

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# ê°¤ëŸ¬ë¦¬ ê²Œì‹œê¸€ ë””í…Œì¼ í¬ë¡¤ë§
def get_post_detail(post_id: str) -> Optional[Dict]:
    """
    ê²Œì‹œê¸€ ë³¸ë¬¸ í¬ë¡¤ë§

    Args:
        post_id: ê²Œì‹œê¸€ ë²ˆí˜¸

    Returns:
        {'post_id', 'title', 'author', 'content', 'images', 'comments'}
    """
    url = f"https://gall.dcinside.com/mgallery/board/view"
    params = {
        'id': GALLERY_ID,
        'no': post_id,
    }

    try:
        response = requests.get(url, params=params, headers=HEADERS, timeout=10)
        response.raise_for_status()

        soup = BeautifulSoup(response.text, 'lxml')

        # ì œëª©
        title_elem = soup.select_one('span.title_subject')
        title = title_elem.text.strip() if title_elem else ''

        # ì‘ì„±ì
        author_elem = soup.select_one('div.gall_writer')
        author = author_elem.get('data-nick', 'ìµëª…') if author_elem else 'ìµëª…'

        # ë³¸ë¬¸ (HTML íƒœê·¸ ì œê±°)
        content_elem = soup.select_one('div.write_div')
        if content_elem:
            # ì´ë¯¸ì§€ íƒœê·¸ ì œê±°í•˜ê³  í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
            for img in content_elem.find_all('img'):
                img.decompose()
            content = content_elem.get_text(separator='\n', strip=True)
        else:
            content = ''

        # ì´ë¯¸ì§€ URL ìˆ˜ì§‘
        images = []
        if content_elem:
            for img in soup.select('div.write_div img'):
                src = img.get('src', '')
                if src and src.startswith('http'):
                    images.append(src)

        # ëŒ“ê¸€ ìˆ˜ì§‘ (ê°„ë‹¨íˆ ëŒ“ê¸€ ë‚´ìš©ë§Œ)
        comments = []
        comment_elems = soup.select('li.ub-content')
        for comment in comment_elems[:10]:  # ìµœëŒ€ 10ê°œë§Œ
            comment_text_elem = comment.select_one('p.usertxt')
            if comment_text_elem:
                comments.append(comment_text_elem.text.strip())

        logger.info(f"ğŸ“ ê²Œì‹œê¸€ {post_id} ë³¸ë¬¸ ìˆ˜ì§‘ ì™„ë£Œ (ë³¸ë¬¸ {len(content)}ì, ëŒ“ê¸€ {len(comments)}ê°œ)")

        return {
            'post_id': post_id,
            'title': title,
            'author': author,
            'content': content,
            'images': images,
            'comments': comments,
        }

    except requests.RequestException as e:  # ê²Œì‹œê¸€ ìš”ì²­ì— ëŒ€í•œ ì‹¤íŒ¨ì— ëŒ€í•œ ì˜ˆì™¸ì²˜ë¦¬
        logger.error(f"âŒ ê²Œì‹œê¸€ {post_id} ìš”ì²­ ì‹¤íŒ¨: {e}")
        return None

    except Exception as e:  # ê²Œì‹œê¸€ íŒŒì‹± ì‹¤íŒ¨ì— ëŒ€í•œ ì˜ˆì™¸ì²˜ë¦¬
        logger.error(f"âŒ ê²Œì‹œê¸€ {post_id} íŒŒì‹± ì‹¤íŒ¨: {e}")
        return None